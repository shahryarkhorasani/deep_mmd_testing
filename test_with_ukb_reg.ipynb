{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "#from mri_3d import *\n",
    "\n",
    "from config_manager import get_directory\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import h5py\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from data_io import ScanDataGenerator\n",
    "from config_manager import get_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "def extract_features_mri(path_to_images='/mnt/30T/adni/ADNI_MPRAGE_VENTRICLES.h5', path_to_model=None, feature_space_layer='dense_1', h5_dict=get_directory.adni_mprage_dict, X_ids=None, Y_ids=None, batch_sizes = 10, scan_dim=(96,96,96), crops=((0, 0), (0, 0), (0, 0)), zoom=1.0):\n",
    "    # feature extraction\n",
    "    \n",
    "    #load model\n",
    "    model = load_model(path_to_model)\n",
    "    #remove output layer\n",
    "    new_model = Model(model.inputs, model.get_layer(feature_space_layer).output)\n",
    "    #load the weights\n",
    "    new_model.set_weights(model.get_weights())\n",
    "    \n",
    "    # loading images using the dictionary to find the scan given an Image_ID:\n",
    "    with open(h5_dict, 'rb') as pk:\n",
    "        imgid = pickle.load(pk)\n",
    "        \n",
    "    img = ScanDataGenerator(path_to_images,img_id=X_ids,dataframe=get_directory.adni_dataframe, crop=crops\n",
    "                                 ,input_dim=scan_dim\n",
    "                                 ,img_to_i=imgid,zooms=zoom)\n",
    "    #img_x, img_x = img\n",
    "    #np_img = np.array(img)\n",
    "    #np_img = np_img[:,0,0,:,:,:,:]\n",
    "    #np_img = np_img.reshape((len(X_ids), scan_dim[0],scan_dim[1],scan_dim[2], 1))\n",
    "    output_X = new_model.predict_generator(img, workers=6, use_multiprocessing=True, verbose=True) #images should have the dimensions: (batch_size,scan_dim[0],scan_dim[1],scan_dim[2],1)\n",
    "    \n",
    "    img = ScanDataGenerator(path_to_images,img_id=Y_ids,dataframe=get_directory.adni_dataframe, crop=crops\n",
    "                                 ,input_dim=scan_dim\n",
    "                                 ,img_to_i=imgid,zooms=zoom)\n",
    "    #img_y, img_y = img\n",
    "    #np_img = np.array(img)\n",
    "    #np_img = np_img[:,0,0,:,:,:,:]\n",
    "    #np_img = np_img.reshape((len(Y_ids), scan_dim[0],scan_dim[1],scan_dim[2], 1)) \n",
    "    output_Y = new_model.predict_generator(img, workers=6, use_multiprocessing=True, verbose=True) #images should have the dimensions: (batch_size,scan_dim[0],scan_dim[1],scan_dim[2],1)\n",
    "    \n",
    "    feats_X = np.array(output_X)\n",
    "    feats_Y = np.array(output_Y)\n",
    "\n",
    "    # end feature extraction\n",
    "    return feats_X.astype(np.float128), feats_Y.astype(np.float128)\n",
    "\n",
    "\n",
    "def compute_p_value(feats_X, feats_Y, n_feats=10):\n",
    "    n, d = feats_X.shape\n",
    "    m = len(feats_Y)\n",
    "    pca = PCA(n_components=n_feats)\n",
    "    feats = np.vstack((feats_X, feats_Y))\n",
    "    feats = pca.fit_transform(feats)\n",
    "    feats_X, feats_Y = feats[:n], feats[n:]\n",
    "    d = n_feats\n",
    "    mean_fX = feats_X.mean(0)\n",
    "    mean_fY = feats_Y.mean(0)\n",
    "    D = mean_fX - mean_fY\n",
    "\n",
    "    eps_ridge = 1e-8    # add ridge to Covariance for numerical stability\n",
    "    all_features = np.concatenate([feats_X, feats_Y])\n",
    "    Cov_D = (1./n + 1./m) * np.cov(all_features.T) + eps_ridge * np.eye(d)\n",
    "\n",
    "    statistic = D.dot(np.linalg.solve(Cov_D, D))\n",
    "    p_val = 1. - stats.chi2.cdf(statistic, d)\n",
    "    return p_val\n",
    "\n",
    "def compute_p_value_mmd(feats_X, feats_Y, n_permute=10000):\n",
    "    stat = compute_mmd(feats_X, feats_Y)\n",
    "    n, m = len(feats_X), len(feats_Y)\n",
    "    l = n + m\n",
    "    feats_Z = np.vstack((feats_X, feats_Y))\n",
    "\n",
    "    resampled_vals = np.empty(n_permute)\n",
    "    for i in range(n_permute):\n",
    "        index = np.random.permutation(l)\n",
    "        feats_X, feats_Y = feats_Z[index[:n]], feats_Z[index[n:]]\n",
    "        resampled_vals[i] = compute_mmd(feats_X, feats_Y)\n",
    "    p_val = np.mean(stat < resampled_vals)\n",
    "    return p_val\n",
    "def compute_mmd(X, Y):\n",
    "    mean_X = X.mean(0)\n",
    "    mean_Y = Y.mean(0)\n",
    "    D = mean_X - mean_Y\n",
    "    stat = np.linalg.norm(D)**2\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adni = pd.read_csv('/mnt/30T/adni/adni_mprage_all.csv')\n",
    "\n",
    "normals_first_scans = adni[adni.DX_Group == 'Normal'].drop_duplicates(subset='Subject_ID')\n",
    "\n",
    "mcis_first_scans = adni[adni.DX_Group == 'MCI'].drop_duplicates(subset='Subject_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/Shahryar.Khorasani/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/Shahryar.Khorasani/anaconda3/envs/keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/Shahryar.Khorasani/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "490/490 [==============================] - 7451s 15s/step\n",
      "287/287 [==============================] - 4325s 15s/step\n"
     ]
    }
   ],
   "source": [
    "x,y = extract_features_mri(path_to_images='/mnt/30T/adni/ADNI_MPRAGE_ALL.h5',\n",
    "    path_to_model=\"/home/Shahryar.Khorasani/adni/models/ukb_reg_age_880902_model.h5\",\n",
    "    feature_space_layer='dense_1',\n",
    "    h5_dict='/mnt/30T/adni/ADNI_MPRAGE_ALL_DICT.pickle',\n",
    "    X_ids=normals_first_scans.Image_ID,\n",
    "    Y_ids=mcis_first_scans.Image_ID,\n",
    "    batch_sizes=2,\n",
    "    scan_dim=(256, 256, 256),\n",
    "    crops=((48, 48), (32, 32),(48, 48)),\n",
    "    zoom=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_n_features(x,y):\n",
    "    n = np.int(np.round(math.sqrt((x.shape[0]+y.shape[0])/2)))\n",
    "    return n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_normal_mci = compute_p_value(x,y,n_feats=get_n_features(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3385760117289323e-07"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_normal_mci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_first_scans = adni[adni.DX_Group == 'AD'].drop_duplicates(subset='Subject_ID')\n",
    "\n",
    "smc_first_scans = adni[adni.DX_Group == 'SMC'].drop_duplicates(subset='Subject_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smc_first_scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad,smc = extract_features_mri(path_to_images='/mnt/30T/adni/ADNI_MPRAGE_ALL.h5',\n",
    "    path_to_model=\"/home/Shahryar.Khorasani/adni/models/ukb_reg_age_880902_model.h5\",\n",
    "    feature_space_layer='dense_1',\n",
    "    h5_dict='/mnt/30T/adni/ADNI_MPRAGE_ALL_DICT.pickle',\n",
    "    X_ids=ad_first_scans.Image_ID,\n",
    "    Y_ids=smc_first_scans.Image_ID,\n",
    "    batch_sizes=2,\n",
    "    scan_dim=(256, 256, 256),\n",
    "    crops=((48, 48), (32, 32),(48, 48)),\n",
    "    zoom=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ad_nromal = compute_p_value(ad,x,n_feats=get_n_features(ad,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8494394238288692e-08"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ad_nromal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ad_mci = compute_p_value(ad,y, n_feats=get_n_features(ad,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005271691403107681"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ad_mci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-218a0e80612e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ad' is not defined"
     ]
    }
   ],
   "source": [
    "len(ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
